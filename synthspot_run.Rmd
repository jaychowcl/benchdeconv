---
title: "synthspot_run"
author: "Jay (Chi Lung) Chow"
date: "2024-05-20"
output: pdf_document
---
## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Importing libraries

```{r libraries}

################  Synthspot ################
#install: https://github.com/saeyslab/synthspot

#install.packages("devtools")
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
#BiocManager::install("DropletUtils")
library(DropletUtils)

devtools::install_github("saeyslab/synthspot")
library(synthspot)
#library(synthvisium)


################  Seurat + Dependencies  ################
#installation: https://satijalab.org/seurat/articles/install_v5

#install.packages('Seurat')
#install.packages("igraph")
##setRepositories(ind = 1:3, addURLs = c('https://satijalab.r-universe.dev', 'https://bnprks.r-universe.dev/'))
##install.packages(c("BPCells", "presto", "glmGamPoi"))
library(Seurat)
library(dplyr)
library(patchwork)



################  Other libraries ################  

################  Set wd  ################  
#setwd("/localdisk/home/s2600569/project")
getwd()

```
## Setting Function Definitions


```{r function_definintions, echo=FALSE}


```

## Importing datasets

You can also embed plots, for example:

```{r import_datasets, echo=FALSE}

################  Import Datasets ################  
# TODO: need to iterate over all files in data dir to import all, or just run each dataset once
#indata_dir <- dir("data")
# TODO: fit the iterate over a readmtx() and ftp to just use geo ascessions https://github.com/satijalab/seurat/issues/4096

### Grab file names ###
data_dir <- dir("data/scRNA_wu") # TODO: make so iterates over every dir
data_dir_mtx <- data_dir[grep("mtx", data_dir)]# TODO: somehow make it so it will rename into matrix.mtx.gz, features.tsv and barcodes.tsv.gz
data_dir_feat <- data_dir[grep("meta", data_dir)]
data_dir_cells <- data_dir[grep("barcode", data_dir)]

### Into Seurat Obj ###
in_data.data <- Read10X(data.dir = "~/project/data/scRNA_wu", gene.column=1) # TODO: need to also account for diff gene column. see https://github.com/satijalab/seurat/issues/1388
in_data <- CreateSeuratObject(counts = in_data.data, project = "scRNA_humanbreastcancer", min.cells = 3, min.features = 200)# TODO: ask if need to alter min.cells and min.features

### Add Metadata  ###
meta<- read.csv("data/scRNA_wu/metadata.csv") # TODO: need to also account for diff metadata file
AddMetaData(in_data, meta)

### Notes ###
# expression_matrix <- ReadMtx(
#   mtx = data_dir_mtx, features = data_dir_feat,
#   cells = data_dir_cells
# )

# Read10X(
#   data.dir,
#   gene.column = 2,
#   cell.column = 1,
#   unique.features = TRUE,
#   strip.suffix = FALSE
# )

```

## Running Synthspot

```{r synthspot_preprocessing, echo=FALSE}
#Tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial
#Otherwise stated, code from Seurat tutorial

################  QC scRNA  ################  
in_data[["percent.mt"]] <- PercentageFeatureSet(in_data, pattern = "^MT-")
#We calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features. We use the set of all genes starting with MT- as a set of mitochondrial genes

### Visualize ###
VlnPlot(in_data, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

### Filter  ###
# pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5) # TODO: Ask if need to filter cells eg. We filter cells that have unique feature counts over 2,500 or less than 200. We filter cells that have >5% mitochondrial counts


################  Normalize scRNA counts  ################ 
in_data_norm <- NormalizeData(in_data, normalization.method = "LogNormalize", scale.factor = 10000)
#While this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules


################  Feature Selection ################  
in_data_norm <- FindVariableFeatures(in_data_norm, selection.method = "vst", nfeatures = 2000)

### Identify the 10 most highly variable genes  ###
top10 <- head(VariableFeatures(in_data_norm), 10)

### plot variable features with and without labels  ###
plot1 <- VariableFeaturePlot(in_data_norm)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2


################  Scaling ################  
all.genes <- rownames(in_data_norm)
in_data_norm <- ScaleData(in_data_norm, features = all.genes)
#we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA

#In Seurat, we also use the ScaleData() function to remove unwanted sources of variation from a single-cell dataset. For example, we could ‘regress out’ heterogeneity associated with (for example) cell cycle stage, or mitochondrial contamination i.e.:
#pbmc <- ScaleData(pbmc, vars.to.regress = "percent.mt")#TODO: Ask if I need to do this

################  Linear Dimension Reduction  ################  
in_data_norm <- RunPCA(in_data_norm, features = VariableFeatures(object = in_data_norm))
print(in_data_norm[["pca"]], dims = 1:50, nfeatures = 5)
### Visualize ###
VizDimLoadings(in_data_norm, dims = 1:2, reduction = "pca")
DimPlot(in_data_norm, reduction = "pca") + NoLegend()
DimHeatmap(in_data_norm, dims = 1, cells = 500, balanced = TRUE)#1 PC
DimHeatmap(in_data_norm, dims = 1:15, cells = 500, balanced = TRUE)#1-15 PC

### Determine Dimensionality  ###
ElbowPlot(in_data_norm)
#We chose 10 here, but encourage users to consider the following: Dendritic cell and NK aficionados may recognize that genes strongly associated with PCs 12 and 13 define rare immune subsets (i.e. MZB1 is a marker for plasmacytoid DCs). However, these groups are so rare, they are difficult to distinguish from background noise for a dataset of this size without prior knowledge.
#therefore choose 13
#TODO: increase elbowplot range ie. increaes x axis to max (50)

### Clustering Cells  ###
in_data_norm <- FindNeighbors(in_data_norm, dims = 1:20) # chose 20 here bc elbowplot doesnt flatten till 20
in_data_norm <- FindClusters(in_data_norm, resolution = 0.5) # TODO: play around with resolution to see dataset clusters -> VISUALIZE TO SEE EFFECTIVENESS
#The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function.
head(Idents(in_data_norm), 5) # Look at cluster IDs of the first 5 cells

################  Non-linear Dimensionality Reduction ################ 
### Run UMAP  ###
in_data_norm <- RunUMAP(in_data_norm, dims = 1:20) #switched from 10->20 # can also try tSNE
DimPlot(in_data_norm, reduction = "umap", label=TRUE)

################  Identify Cluster Biomarkers ################
in_data_norm.markers <- FindAllMarkers(in_data_norm, only.pos = TRUE)#FOCUS
in_data_norm.markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1)
### Visualize Marker Expression ###
FeaturePlot(in_data_norm, features = c("MS4A1", "GNLY", "CD3E", "CD14", "FCER1A", "FCGR3A", "LYZ", "PPBP",
    "CD8A"))

in_data_norm.markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10
DoHeatmap(in_data_norm, features = top10$gene) + NoLegend()

```

```{r synthspot_normalize, echo=FALSE}





```

